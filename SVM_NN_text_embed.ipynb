{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg55CWKlYtFnVSzykFi7CO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36ad7261415f4f2dacd1e4c7061dff0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_660763b4fb5a44538e13a48ac56c5e1c",
              "IPY_MODEL_90a0f6dd09ee4b7d96ae2f1cc6e69928",
              "IPY_MODEL_0bbe29e058f141eaa35ebbb0c7729766"
            ],
            "layout": "IPY_MODEL_a136e94ccccc493c8d7c7c2bd0622048"
          }
        },
        "660763b4fb5a44538e13a48ac56c5e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f90a77b0d54231b591770b7542461f",
            "placeholder": "​",
            "style": "IPY_MODEL_3e989c85f43b4b96ac39e31ddd0a203e",
            "value": "config.json: 100%"
          }
        },
        "90a0f6dd09ee4b7d96ae2f1cc6e69928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ffabeb546446f48c7c27df0bf30194",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ac28edf948449c8a3270c44491f3e83",
            "value": 385
          }
        },
        "0bbe29e058f141eaa35ebbb0c7729766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e3d44449b745fb849dc5248175b223",
            "placeholder": "​",
            "style": "IPY_MODEL_37facb69c42c4dd8ba89d170d02a4224",
            "value": " 385/385 [00:00&lt;00:00, 6.23kB/s]"
          }
        },
        "a136e94ccccc493c8d7c7c2bd0622048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f90a77b0d54231b591770b7542461f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e989c85f43b4b96ac39e31ddd0a203e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51ffabeb546446f48c7c27df0bf30194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac28edf948449c8a3270c44491f3e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64e3d44449b745fb849dc5248175b223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37facb69c42c4dd8ba89d170d02a4224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83656126986a4d91bd57a17bf9c72127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_966dcad9e28f4291b021b963e82c4c54",
              "IPY_MODEL_3f5d354038d94a7c8814e2bfd8c214ad",
              "IPY_MODEL_9a1b9770781e4340a433b0476b66ca60"
            ],
            "layout": "IPY_MODEL_79206eb453a44c15aa240937a59aaecf"
          }
        },
        "966dcad9e28f4291b021b963e82c4c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b646344e2f0e4664801f1ffea940b59e",
            "placeholder": "​",
            "style": "IPY_MODEL_52f4196a30c2481c82c593e53494ca4d",
            "value": "vocab.txt: 100%"
          }
        },
        "3f5d354038d94a7c8814e2bfd8c214ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ae798b3e144446fb24dab164facb38e",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f03d36733d34e9ba613511b68d3eea1",
            "value": 213450
          }
        },
        "9a1b9770781e4340a433b0476b66ca60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9668d2533be6438aaa6c6887119dba2e",
            "placeholder": "​",
            "style": "IPY_MODEL_caf71256e563434da12ba537af80fab0",
            "value": " 213k/213k [00:00&lt;00:00, 2.05MB/s]"
          }
        },
        "79206eb453a44c15aa240937a59aaecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b646344e2f0e4664801f1ffea940b59e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f4196a30c2481c82c593e53494ca4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ae798b3e144446fb24dab164facb38e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f03d36733d34e9ba613511b68d3eea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9668d2533be6438aaa6c6887119dba2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf71256e563434da12ba537af80fab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "000af92b27f94dc486fe63fa98d24cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6eb17e6f5cf34fb28e88c2f03a7d250c",
              "IPY_MODEL_6e26dd4b3ec8457c8427037287df375b",
              "IPY_MODEL_17cd1c10ef6540e3b06faeada6248924"
            ],
            "layout": "IPY_MODEL_727c0c424f2d4eafa4bdeb22c98e830b"
          }
        },
        "6eb17e6f5cf34fb28e88c2f03a7d250c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e6c6a90066441ab9b67cfa59b8f9512",
            "placeholder": "​",
            "style": "IPY_MODEL_62cc777e0e8546d894e0ec3d7bb59c57",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6e26dd4b3ec8457c8427037287df375b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc09f6df709a41c8a26883989adde291",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca8b8df4c4364a34af42f56603cd11e1",
            "value": 435778770
          }
        },
        "17cd1c10ef6540e3b06faeada6248924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_467cb5a154aa4782b0d5af6e8795d244",
            "placeholder": "​",
            "style": "IPY_MODEL_02530eeb552f4267b4e3a5275a8eb1ce",
            "value": " 436M/436M [00:13&lt;00:00, 29.0MB/s]"
          }
        },
        "727c0c424f2d4eafa4bdeb22c98e830b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6c6a90066441ab9b67cfa59b8f9512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62cc777e0e8546d894e0ec3d7bb59c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc09f6df709a41c8a26883989adde291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8b8df4c4364a34af42f56603cd11e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "467cb5a154aa4782b0d5af6e8795d244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02530eeb552f4267b4e3a5275a8eb1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshimR/web3j-workshop/blob/master/SVM_NN_text_embed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install optuna --quiet\n",
        "!pip install shap --quiet"
      ],
      "metadata": {
        "id": "QihxB57UXZf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8323d63f-a0fe-4b29-9a97-79492d7d575c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/380.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/380.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.2/538.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import optuna # for searching best hyperparameter\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import shap\n",
        "from google.colab import files\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "w3Vd1KJvXdE9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Xffd0oYvXuSF",
        "outputId": "462ab6ed-7bd2-4799-d75e-2db64f72d364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f893d8b0-b7bb-422d-9517-d9fb401e6fa0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f893d8b0-b7bb-422d-9517-d9fb401e6fa0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sym_w_embeddings_corrected.csv to sym_w_embeddings_corrected.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is used for feature scaling and wont be needed in the main model"
      ],
      "metadata": {
        "id": "Tpa6uT-e-mms"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVQ_CP3mz0i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset to preprocess it for text embedding and semantic search usage\n",
        "data = pd.read_csv('/content/symbipredict_2022.csv')\n",
        "\n",
        "# Creating a text description for each row in the dataset by concatenating symptom names if present (1)\n",
        "def create_symptom_description(row):\n",
        "    symptoms = [col.replace('_', ' ') for col in row.index if row[col] == 1]\n",
        "    return ', '.join(symptoms)\n",
        "\n",
        "# Apply the function to each row in the DataFrame\n",
        "data['symptom_description'] = data.apply(create_symptom_description, axis=1)\n",
        "\n",
        "# Check the modified DataFrame and export it to a CSV file for verification\n",
        "data.to_csv('/content/processed_symbipredict_2022.csv', index=False)\n",
        "data.head(), data['symptom_description'].head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmuMLEUOXJvO",
        "outputId": "4ddeaa9e-1942-4270-e07f-113e8f0779aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
              " 0        1          1                     1                    0          0   \n",
              " 1        0          1                     1                    0          0   \n",
              " 2        1          0                     1                    0          0   \n",
              " 3        1          1                     0                    0          0   \n",
              " 4        1          1                     1                    0          0   \n",
              " \n",
              "    chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  scurring  \\\n",
              " 0       0           0             0        0                 0  ...         0   \n",
              " 1       0           0             0        0                 0  ...         0   \n",
              " 2       0           0             0        0                 0  ...         0   \n",
              " 3       0           0             0        0                 0  ...         0   \n",
              " 4       0           0             0        0                 0  ...         0   \n",
              " \n",
              "    skin_peeling  silver_like_dusting  small_dents_in_nails  \\\n",
              " 0             0                    0                     0   \n",
              " 1             0                    0                     0   \n",
              " 2             0                    0                     0   \n",
              " 3             0                    0                     0   \n",
              " 4             0                    0                     0   \n",
              " \n",
              "    inflammatory_nails  blister  red_sore_around_nose  yellow_crust_ooze  \\\n",
              " 0                   0        0                     0                  0   \n",
              " 1                   0        0                     0                  0   \n",
              " 2                   0        0                     0                  0   \n",
              " 3                   0        0                     0                  0   \n",
              " 4                   0        0                     0                  0   \n",
              " \n",
              "           prognosis                                symptom_description  \n",
              " 0  Fungal Infection  itching, skin rash, nodal skin eruptions, disc...  \n",
              " 1  Fungal Infection  skin rash, nodal skin eruptions, dischromic  p...  \n",
              " 2  Fungal Infection  itching, nodal skin eruptions, dischromic  pat...  \n",
              " 3  Fungal Infection            itching, skin rash, dischromic  patches  \n",
              " 4  Fungal Infection           itching, skin rash, nodal skin eruptions  \n",
              " \n",
              " [5 rows x 134 columns],\n",
              " 0    itching, skin rash, nodal skin eruptions, disc...\n",
              " 1    skin rash, nodal skin eruptions, dischromic  p...\n",
              " 2    itching, nodal skin eruptions, dischromic  pat...\n",
              " 3              itching, skin rash, dischromic  patches\n",
              " 4             itching, skin rash, nodal skin eruptions\n",
              " Name: symptom_description, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_frame.to_csv('/content/embd_symbipredict_2022.csv')"
      ],
      "metadata": {
        "id": "dBgAbZDMn6Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "def load_data(filepath):\n",
        "    return pd.read_csv(filepath)\n",
        "\n",
        "# Plot the distribution of each disease (prognosis)\n",
        "def plot_disease_distribution(df):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    disease_counts = df['prognosis'].value_counts()\n",
        "    sns.barplot(y=disease_counts.index, x=disease_counts.values, palette='viridis')\n",
        "    plt.title('Disease Distribution in Dataset')\n",
        "    plt.xlabel('Frequency')\n",
        "    plt.ylabel('Diseases')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the prevalence of symptoms in the dataset\n",
        "def plot_symptom_prevalence(df):\n",
        "    symptoms = df.columns[:-1]  # exclude the last column which is prognosis\n",
        "    symptom_counts = df[symptoms].sum().sort_values(ascending=False)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.barplot(y=symptom_counts.index[:30], x=symptom_counts.values[:30], palette='viridis')  # Top 30 symptoms\n",
        "    plt.title('Top 30 Common Symptoms in Dataset')\n",
        "    plt.xlabel('Frequency of Symptoms')\n",
        "    plt.ylabel('Symptoms')\n",
        "    plt.show()\n",
        "\n",
        "# Plot a heatmap of symptom correlations\n",
        "def plot_symptom_correlation(df):\n",
        "    symptoms = df.columns[:-1]  # exclude the last column which is prognosis\n",
        "    correlation_matrix = df[symptoms].corr()\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    sns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=False)\n",
        "    plt.title('Correlation Matrix of Symptoms')\n",
        "    plt.show()\n",
        "\n",
        "# Main function to run the EDA\n",
        "def run_eda(filepath):\n",
        "    df = load_data(filepath)\n",
        "    plot_disease_distribution(df)\n",
        "    plot_symptom_prevalence(df)\n",
        "    plot_symptom_correlation(df)"
      ],
      "metadata": {
        "id": "zbv6NBmk0A36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = data[['symptom_description','prognosis']]"
      ],
      "metadata": {
        "id": "nCPk1a32aoci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute descriptive statistics for the 'prognosis' column to see the distribution of diseases\n",
        "disease_distribution = data_frame['prognosis'].value_counts()\n",
        "\n",
        "# Display the disease distribution\n",
        "disease_distribution"
      ],
      "metadata": {
        "id": "HYPLUeJg1SyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part was done to create a dataset with embeddings"
      ],
      "metadata": {
        "id": "WGlEM2Fl_EUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer and model from Hugging Face's Transformers\n",
        "emb_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "emb_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "# Function to generate embeddings for a given text\n",
        "def generate_embeddings(text):\n",
        "    encoded_input = emb_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = emb_model(**encoded_input)\n",
        "    embeddings = output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    return embeddings\n",
        "\n",
        "# Apply the function to generate embeddings for the 'symptom_description' column\n",
        "data_frame['embeddings'] = data_frame['symptom_description'].apply(generate_embeddings)\n",
        "\n",
        "# Optionally save the new dataframe with embeddings to a new CSV for further use\n",
        "data_frame.to_csv('sym_w_embeddings2.csv', index=False)\n",
        "\n",
        "# Print some of the generated embeddings to confirm they are correct\n",
        "print(data_frame[['symptom_description', 'embeddings']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567,
          "referenced_widgets": [
            "36ad7261415f4f2dacd1e4c7061dff0a",
            "660763b4fb5a44538e13a48ac56c5e1c",
            "90a0f6dd09ee4b7d96ae2f1cc6e69928",
            "0bbe29e058f141eaa35ebbb0c7729766",
            "a136e94ccccc493c8d7c7c2bd0622048",
            "04f90a77b0d54231b591770b7542461f",
            "3e989c85f43b4b96ac39e31ddd0a203e",
            "51ffabeb546446f48c7c27df0bf30194",
            "5ac28edf948449c8a3270c44491f3e83",
            "64e3d44449b745fb849dc5248175b223",
            "37facb69c42c4dd8ba89d170d02a4224",
            "83656126986a4d91bd57a17bf9c72127",
            "966dcad9e28f4291b021b963e82c4c54",
            "3f5d354038d94a7c8814e2bfd8c214ad",
            "9a1b9770781e4340a433b0476b66ca60",
            "79206eb453a44c15aa240937a59aaecf",
            "b646344e2f0e4664801f1ffea940b59e",
            "52f4196a30c2481c82c593e53494ca4d",
            "9ae798b3e144446fb24dab164facb38e",
            "4f03d36733d34e9ba613511b68d3eea1",
            "9668d2533be6438aaa6c6887119dba2e",
            "caf71256e563434da12ba537af80fab0",
            "000af92b27f94dc486fe63fa98d24cc1",
            "6eb17e6f5cf34fb28e88c2f03a7d250c",
            "6e26dd4b3ec8457c8427037287df375b",
            "17cd1c10ef6540e3b06faeada6248924",
            "727c0c424f2d4eafa4bdeb22c98e830b",
            "0e6c6a90066441ab9b67cfa59b8f9512",
            "62cc777e0e8546d894e0ec3d7bb59c57",
            "bc09f6df709a41c8a26883989adde291",
            "ca8b8df4c4364a34af42f56603cd11e1",
            "467cb5a154aa4782b0d5af6e8795d244",
            "02530eeb552f4267b4e3a5275a8eb1ce"
          ]
        },
        "id": "H6envhrRfZS2",
        "outputId": "b5aa8e1a-0e16-40eb-c7d7-967b956f0aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36ad7261415f4f2dacd1e4c7061dff0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83656126986a4d91bd57a17bf9c72127"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "000af92b27f94dc486fe63fa98d24cc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-ee7ec519fda6>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_frame['embeddings'] = data_frame['symptom_description'].apply(generate_embeddings)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 symptom_description  \\\n",
            "0  itching, skin rash, nodal skin eruptions, disc...   \n",
            "1  skin rash, nodal skin eruptions, dischromic  p...   \n",
            "2  itching, nodal skin eruptions, dischromic  pat...   \n",
            "3            itching, skin rash, dischromic  patches   \n",
            "4           itching, skin rash, nodal skin eruptions   \n",
            "\n",
            "                                          embeddings  \n",
            "0  [0.300389, 0.010864246, -0.40300804, 0.2143276...  \n",
            "1  [0.39868072, -0.112185195, -0.33901146, 0.1459...  \n",
            "2  [0.31049445, 0.011516023, -0.41578156, 0.19552...  \n",
            "3  [0.35473484, -0.046607442, -0.38146266, 0.2751...  \n",
            "4  [0.37643713, 0.08506728, -0.40587324, 0.328377...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming embeddings are generated as numpy arrays (from your previous code snippet)\n",
        "data_frame['embeddings'] = data_frame['symptom_description'].apply(lambda x: ','.join(map(str, generate_embeddings(x))))\n",
        "\n",
        "# Now save to CSV\n",
        "data_frame.to_csv('sym_w_embeddings_corrected.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYR3ojvSialr",
        "outputId": "6bac147d-366a-4078-9823-328da17b0f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-964644922b94>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_frame['embeddings'] = data_frame['symptom_description'].apply(lambda x: ','.join(map(str, generate_embeddings(x))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_ndarray(string):\n",
        "    try:\n",
        "        return np.array(list(map(float, string.split(','))))\n",
        "    except ValueError:\n",
        "        return np.array([])  # Return an empty array if conversion fails\n",
        "\n",
        "# Load your dataframe\n",
        "data_frame = pd.read_csv('/content/sym_w_embeddings_corrected.csv')\n",
        "data_frame['embeddings'] = data_frame['embeddings'].apply(convert_to_ndarray)\n",
        "\n",
        "# Verify the types again\n",
        "print(data_frame['embeddings'].apply(type).unique())  # Should show <class 'numpy.ndarray'>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbIWWg3YlnTK",
        "outputId": "a6c6d97c-b9c6-480c-cd6e-87c769af5428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<class 'numpy.ndarray'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "MWa-yEA3tc9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'embeddings' column contains the embeddings and is in an appropriate format\n",
        "X = list(data_frame['embeddings'])\n",
        "y = data_frame['prognosis']\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "tWre2E8gn-8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.LongTensor(y_test)\n",
        "\n",
        "# Create training and testing datasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Update dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=12, shuffle=False)"
      ],
      "metadata": {
        "id": "6fhXSPzfQGVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple feedforward neural network (Multilayer Perceptron or MLP)"
      ],
      "metadata": {
        "id": "LBcdOOtBx5_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
        "# Setup the SVM model\n",
        "svm_model = svm.SVC(kernel='linear', C = 0.1785379499667778)"
      ],
      "metadata": {
        "id": "T8ZImr-G04tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class DiseasePredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        The main model to predict diseases\n",
        "        \"\"\"\n",
        "        super(DiseasePredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features=768, out_features=462)\n",
        "        self.fc2 = nn.Linear(462, 462)  # Second hidden layer\n",
        "        self.fc3 = nn.Linear(462, 462)  # Third hidden layer\n",
        "        self.output = nn.Linear(462, 41)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.0015) # Dropout layer very small\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_qbZP9jiRUGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        log_prob = torch.nn.functional.log_softmax(input, dim=-1)\n",
        "        weight = input.new_ones(input.size()) * self.smoothing / (input.size(-1) - 1.)\n",
        "        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n",
        "        loss = (-weight * log_prob).sum(dim=-1).mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "ZYRUKs29RXH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the network, loss function, and optimizer\n",
        "predict_model = DiseasePredictor()\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing = 0.1) # to prevent overfitting\n",
        "optimizer = optim.Adam(predict_model.parameters(), lr = 0.0006312703277951093) # tuned\n",
        "scheduler = ExponentialLR(optimizer, gamma = 0.9053013456459507) # to update lerning rate"
      ],
      "metadata": {
        "id": "Vqm-IiX7RcLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for neural network\n",
        "def train_model():\n",
        "  predict_model.train()\n",
        "  for epoch in range(55):  # 55 , based on the best result produced during hypertuning\n",
        "      for inputs, labels in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          outputs = predict_model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      scheduler.step()\n",
        "      print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "  return predict_model"
      ],
      "metadata": {
        "id": "D1O7qTtysgjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkedWZmdTPb1",
        "outputId": "78528315-ab99-4340-c3c0-bb11fedc20a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6941301822662354\n",
            "Epoch 2, Loss: 0.6944928765296936\n",
            "Epoch 3, Loss: 0.6940318942070007\n",
            "Epoch 4, Loss: 0.6941406726837158\n",
            "Epoch 5, Loss: 0.6940476894378662\n",
            "Epoch 6, Loss: 0.6942513585090637\n",
            "Epoch 7, Loss: 0.6940442323684692\n",
            "Epoch 8, Loss: 0.6940886378288269\n",
            "Epoch 9, Loss: 0.6940945386886597\n",
            "Epoch 10, Loss: 0.6940370798110962\n",
            "Epoch 11, Loss: 0.6941156387329102\n",
            "Epoch 12, Loss: 0.6940478086471558\n",
            "Epoch 13, Loss: 0.6940494775772095\n",
            "Epoch 14, Loss: 0.6942534446716309\n",
            "Epoch 15, Loss: 0.6940634250640869\n",
            "Epoch 16, Loss: 0.6955879926681519\n",
            "Epoch 17, Loss: 0.6941063404083252\n",
            "Epoch 18, Loss: 0.6940407156944275\n",
            "Epoch 19, Loss: 0.6941575407981873\n",
            "Epoch 20, Loss: 0.6940573453903198\n",
            "Epoch 21, Loss: 0.6942717432975769\n",
            "Epoch 22, Loss: 0.6941140294075012\n",
            "Epoch 23, Loss: 0.6940861344337463\n",
            "Epoch 24, Loss: 0.6941143870353699\n",
            "Epoch 25, Loss: 0.6941884756088257\n",
            "Epoch 26, Loss: 0.6940481662750244\n",
            "Epoch 27, Loss: 0.6940653920173645\n",
            "Epoch 28, Loss: 0.6940255165100098\n",
            "Epoch 29, Loss: 0.6940867900848389\n",
            "Epoch 30, Loss: 0.6940445899963379\n",
            "Epoch 31, Loss: 0.6940513849258423\n",
            "Epoch 32, Loss: 0.6940621137619019\n",
            "Epoch 33, Loss: 0.6942380666732788\n",
            "Epoch 34, Loss: 0.6940263509750366\n",
            "Epoch 35, Loss: 0.694092869758606\n",
            "Epoch 36, Loss: 0.694075882434845\n",
            "Epoch 37, Loss: 0.6940193176269531\n",
            "Epoch 38, Loss: 0.694034218788147\n",
            "Epoch 39, Loss: 0.6940639019012451\n",
            "Epoch 40, Loss: 0.6940487623214722\n",
            "Epoch 41, Loss: 0.6940158009529114\n",
            "Epoch 42, Loss: 0.6940606832504272\n",
            "Epoch 43, Loss: 0.6940078735351562\n",
            "Epoch 44, Loss: 0.6941162943840027\n",
            "Epoch 45, Loss: 0.6942554712295532\n",
            "Epoch 46, Loss: 0.6941096186637878\n",
            "Epoch 47, Loss: 0.6940600275993347\n",
            "Epoch 48, Loss: 0.6940279006958008\n",
            "Epoch 49, Loss: 0.6941564679145813\n",
            "Epoch 50, Loss: 0.6942018866539001\n",
            "Epoch 51, Loss: 0.6942582130432129\n",
            "Epoch 52, Loss: 0.6941574215888977\n",
            "Epoch 53, Loss: 0.6941845417022705\n",
            "Epoch 54, Loss: 0.6942091584205627\n",
            "Epoch 55, Loss: 0.694488525390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trianing for svm\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "svm_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Precision\n",
        "svm_precision = precision_score(y_test, y_pred, average='macro')\n",
        "# Recall\n",
        "svm_recall = recall_score(y_test,y_pred ,average='macro')\n",
        "# F1 score\n",
        "svm_f1 = f1_score(y_test,y_pred,average='macro')\n",
        "\n",
        "print(f'Accuracy: {svm_accuracy:.2f}, Precision {svm_precision:.2f},  Recall {svm_recall:.2f} and F1 score {svm_f1:.2f}')\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "id": "7TOpR46iO5o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective_svm(trial):\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
        "\n",
        "    if kernel in ['rbf', 'sigmoid']:\n",
        "        gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
        "        svm = SVC(kernel=kernel, C=C, gamma=gamma)\n",
        "    elif kernel == 'poly':\n",
        "        gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
        "        degree = trial.suggest_int('degree', 1, 5)\n",
        "        svm = SVC(kernel=kernel, C=C, gamma=gamma, degree=degree)\n",
        "    else:\n",
        "        svm = SVC(kernel=kernel, C=C)\n",
        "\n",
        "    score = cross_val_score(svm, X_train, y_train, n_jobs=-1, cv=3)\n",
        "    accuracy = score.mean()\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective_svm, n_trials=50)\n",
        "\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best cross-validation score:\", study.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pRaKrJG087H",
        "outputId": "f96e223b-5db0-4bdb-af0b-7f9295b3a933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-22 12:47:25,958] A new study created in memory with name: no-name-79b45ea6-fe26-4a74-ac6f-ab9ef89dd023\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "[I 2024-04-22 12:47:29,600] Trial 0 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.1785379499667778}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:47:31,303] Trial 1 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 139.5531627841051, 'gamma': 1.4592309550121214, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:47:34,795] Trial 2 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 930.4133200808059}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:47:36,024] Trial 3 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.3192000762640428}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:47:53,193] Trial 4 finished with value: 0.026461696910511836 and parameters: {'kernel': 'poly', 'C': 0.012824317080080113, 'gamma': 0.00023449760497266074, 'degree': 4}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:47:55,658] Trial 5 finished with value: 0.99899218946838 and parameters: {'kernel': 'rbf', 'C': 2.0232343526651047, 'gamma': 0.00022496707613003358}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:47:56,901] Trial 6 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 0.005227598795961909, 'gamma': 0.2340775731282505, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:47:58,114] Trial 7 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.012699302837238653}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:00,548] Trial 8 finished with value: 0.9997478567826525 and parameters: {'kernel': 'rbf', 'C': 21.255108905837698, 'gamma': 0.03494235284440349}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:03,524] Trial 9 finished with value: 1.0 and parameters: {'kernel': 'rbf', 'C': 33.32497303794628, 'gamma': 0.026955228040556053}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:20,606] Trial 10 finished with value: 0.026461696910511836 and parameters: {'kernel': 'sigmoid', 'C': 0.00013044677645075074, 'gamma': 0.003571497613208215}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:21,824] Trial 11 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 264.31487985838635, 'gamma': 7.789205358133171, 'degree': 2}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:32,068] Trial 12 finished with value: 0.12626695772722715 and parameters: {'kernel': 'sigmoid', 'C': 8288.176641142827, 'gamma': 6.486087924937385}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:48:33,308] Trial 13 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.7547422511125329}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:34,448] Trial 14 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 9.425855945624297, 'gamma': 0.8194592303661481, 'degree': 1}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:48:35,605] Trial 15 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.09796333857982076}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:36,822] Trial 16 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 409.65314833080913, 'gamma': 0.6289727312315062, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:53,827] Trial 17 finished with value: 0.026461696910511836 and parameters: {'kernel': 'sigmoid', 'C': 0.00019625299454041953, 'gamma': 0.05506034708551389}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:55,431] Trial 18 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 4.026804184146244, 'gamma': 0.002086832943153879, 'degree': 3}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:48:56,943] Trial 19 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.09376449292386431}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:48:58,255] Trial 20 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 57.7534787442254, 'gamma': 1.871354445004663, 'degree': 4}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:48:59,504] Trial 21 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 1140.7544342401432}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:00,672] Trial 22 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 1711.977068330519}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:02,698] Trial 23 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 9197.520801195044}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:04,471] Trial 24 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 68.16858330705497}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:05,723] Trial 25 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 123.44131616122908}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:08,698] Trial 26 finished with value: 0.9967229005122529 and parameters: {'kernel': 'rbf', 'C': 1270.1238255292185, 'gamma': 0.1375410748759613}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:16,892] Trial 27 finished with value: 0.7623450119667972 and parameters: {'kernel': 'sigmoid', 'C': 0.13921285961878846, 'gamma': 0.005475068219773815}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:18,346] Trial 28 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.0015899145043881506}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:19,619] Trial 29 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.4702770585177163}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:22,972] Trial 30 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 5.58975301641747, 'gamma': 2.088866944862442, 'degree': 3}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:24,553] Trial 31 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.24800774757518573}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:25,812] Trial 32 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.028822840328763758}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:27,080] Trial 33 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 1.1880511406315897}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:42,264] Trial 34 finished with value: 0.23311393252319698 and parameters: {'kernel': 'poly', 'C': 0.03435977564130038, 'gamma': 0.0008327260274666655, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:44,580] Trial 35 finished with value: 0.9967229005122529 and parameters: {'kernel': 'rbf', 'C': 2.3977815014979784, 'gamma': 0.22558731305623508}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:45,839] Trial 36 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 2908.12243063897}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:47,128] Trial 37 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.005882607729475319}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:50,019] Trial 38 finished with value: 1.0 and parameters: {'kernel': 'rbf', 'C': 12.577312897684147, 'gamma': 0.01297784723839599}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:51,317] Trial 39 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 328.42097931400644, 'gamma': 2.276659936268187, 'degree': 4}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:49:52,576] Trial 40 finished with value: 1.0 and parameters: {'kernel': 'linear', 'C': 0.035200708438313466}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:53,846] Trial 41 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 0.0019669851586705893, 'gamma': 0.26469128237199957, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:55,102] Trial 42 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 0.007992468924867787, 'gamma': 0.0899079880457116, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:49:56,284] Trial 43 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 0.00031184747803531605, 'gamma': 0.6010538707227248, 'degree': 4}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:50:11,504] Trial 44 finished with value: 0.026461696910511836 and parameters: {'kernel': 'sigmoid', 'C': 0.0022816414664998904, 'gamma': 3.7070786299456877}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:50:12,737] Trial 45 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 0.4223262207970121, 'gamma': 0.3840586068576807, 'degree': 2}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:50:14,208] Trial 46 finished with value: 1.0 and parameters: {'kernel': 'poly', 'C': 20.764048630463098, 'gamma': 1.0679799734199056, 'degree': 5}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:50:24,431] Trial 47 finished with value: 0.09652072853571304 and parameters: {'kernel': 'sigmoid', 'C': 1.1588350892384585, 'gamma': 0.11790143328188396}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "<ipython-input-7-7785bead97cc>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
            "[I 2024-04-22 12:50:26,100] Trial 48 finished with value: 1.0 and parameters: {'kernel': 'rbf', 'C': 3963.7474299284527, 'gamma': 0.00011000223369321461}. Best is trial 0 with value: 1.0.\n",
            "<ipython-input-7-7785bead97cc>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-04-22 12:50:28,987] Trial 49 finished with value: 0.99899218946838 and parameters: {'kernel': 'linear', 'C': 0.00045739022472549837}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'kernel': 'linear', 'C': 0.1785379499667778}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to find the best hyperparameters for nn\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to tune\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "    num_units = trial.suggest_int('num_units', 50, 500)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
        "    decay = trial.suggest_uniform('decay', 0.8, 0.999)  # Learning rate decay\n",
        "    num_epochs = trial.suggest_int('num_epochs', 10, 100)  # Dynamic number of epochs\n",
        "    batch_size = trial.suggest_int('batch_size', 8, 64)  # Dynamic batch size\n",
        "\n",
        "    # Model definition based on hyperparameters\n",
        "    model = nn.Sequential()\n",
        "    for i in range(num_layers):\n",
        "        model.add_module(f\"linear_{i}\", nn.Linear(in_features=768 if i == 0 else num_units, out_features=num_units))\n",
        "        model.add_module(f\"relu_{i}\", nn.ReLU())\n",
        "        model.add_module(f\"dropout_{i}\", nn.Dropout(p=dropout_rate))\n",
        "    model.add_module(\"output\", nn.Linear(in_features=num_units, out_features=len(set(y))))\n",
        "    model.add_module(\"softmax\", nn.LogSoftmax(dim=1))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "    scheduler = ExponentialLR(optimizer, gamma = decay) # to update lerning rate\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "      for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      scheduler.step()\n",
        "      # to evaluate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_test_tensor = torch.FloatTensor(X_test)\n",
        "        y_test_tensor = torch.LongTensor(y_test)\n",
        "        outputs = model(X_test_tensor)\n",
        "        loss = criterion(outputs, y_test_tensor)\n",
        "    return loss.item()\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)  # Run 100 different trials\n",
        "\n",
        "print(\"Best hyperparameters: \", study.best_params)"
      ],
      "metadata": {
        "id": "3xZphZ4I-QwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(predict_model, test_loader):\n",
        "    predict_model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = predict_model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    class_report = classification_report(all_labels, all_preds)\n",
        "    print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "    print(f'F1 Score: {f1:.4f}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Create test_loader with correct configurations similar to train_loader\n",
        "test_loader = DataLoader(TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test)), batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(trained_model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLu8jjGeTXEO",
        "outputId": "d9056807-85a7-4f1d-c6ff-aa2c8c9fbf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        29\n",
            "           1       1.00      1.00      1.00        25\n",
            "           2       1.00      1.00      1.00        29\n",
            "           3       1.00      1.00      1.00        26\n",
            "           4       1.00      1.00      1.00        24\n",
            "           5       1.00      1.00      1.00        29\n",
            "           6       1.00      1.00      1.00        21\n",
            "           7       1.00      1.00      1.00        20\n",
            "           8       1.00      1.00      1.00        24\n",
            "           9       1.00      1.00      1.00        20\n",
            "          10       1.00      1.00      1.00        29\n",
            "          11       1.00      1.00      1.00        21\n",
            "          12       1.00      1.00      1.00        18\n",
            "          13       1.00      1.00      1.00        25\n",
            "          14       1.00      1.00      1.00        22\n",
            "          15       1.00      1.00      1.00        31\n",
            "          16       1.00      1.00      1.00        24\n",
            "          17       1.00      1.00      1.00        25\n",
            "          18       1.00      1.00      1.00        25\n",
            "          19       1.00      1.00      1.00        24\n",
            "          20       1.00      1.00      1.00        23\n",
            "          21       1.00      1.00      1.00        25\n",
            "          22       1.00      1.00      1.00        28\n",
            "          23       1.00      1.00      1.00        20\n",
            "          24       1.00      1.00      1.00        31\n",
            "          25       1.00      1.00      1.00        20\n",
            "          26       1.00      1.00      1.00        23\n",
            "          27       1.00      1.00      1.00        27\n",
            "          28       1.00      1.00      1.00        20\n",
            "          29       1.00      1.00      1.00        16\n",
            "          30       1.00      1.00      1.00        20\n",
            "          31       1.00      1.00      1.00        18\n",
            "          32       1.00      1.00      1.00        26\n",
            "          33       1.00      1.00      1.00        26\n",
            "          34       1.00      1.00      1.00        27\n",
            "          35       1.00      1.00      1.00        29\n",
            "          36       1.00      1.00      1.00        28\n",
            "          37       1.00      1.00      1.00        29\n",
            "          38       1.00      1.00      1.00        22\n",
            "          39       1.00      1.00      1.00        24\n",
            "          40       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00       993\n",
            "   macro avg       1.00      1.00      1.00       993\n",
            "weighted avg       1.00      1.00      1.00       993\n",
            "\n",
            "Confusion Matrix:\n",
            " [[29  0  0 ...  0  0  0]\n",
            " [ 0 25  0 ...  0  0  0]\n",
            " [ 0  0 29 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 22  0  0]\n",
            " [ 0  0  0 ...  0 24  0]\n",
            " [ 0  0  0 ...  0  0 20]]\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_database = np.stack(data_frame['embeddings'].values)  # Stack embeddings into a matrix\n",
        "symptoms_db = data_frame['symptom_description'].tolist()  # List of all symptom descriptions\n"
      ],
      "metadata": {
        "id": "kNUUK4Qpiiqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your model and the explainer\n",
        "explainer = shap.GradientExplainer(predict_model, data=X_train_tensor)  # Use a subset of training data to initialize\n",
        "shap_values = explainer.shap_values(X_test_tensor[0:1])  # Explain a single prediction\n",
        "pyplot(shap.summary_plot(shap_values, X_test_tensor[0:1]))\n"
      ],
      "metadata": {
        "id": "726-vZEAiXiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "outputId": "6fc458ce-bde9-4b08-da05-80ce00bc0423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1150x660 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(input_embedding, embeddings_database, top_k=1):\n",
        "    # Calculate cosine similarities\n",
        "    similarities = np.dot(embeddings_database, input_embedding) / (np.linalg.norm(embeddings_database, axis=1) * np.linalg.norm(input_embedding))\n",
        "    # Get top_k indices with highest similarity\n",
        "    top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "    return top_k_indices\n"
      ],
      "metadata": {
        "id": "YiqneieDipYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.GradientExplainer(predict_model, torch.FloatTensor(embeddings_database[:100]))  # Using first 100 entries for initialization"
      ],
      "metadata": {
        "id": "QgwGt3tgbU-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a matplotlib figure to a Tkinter image\n",
        "def fig_to_img(fig):\n",
        "    # Save the plot to a PNG in memory\n",
        "    fig.savefig('temp_plot.png', bbox_inches='tight')\n",
        "    # Open this image in PIL\n",
        "    pil_img = Image.open('temp_plot.png')\n",
        "    # Convert to Tkinter format\n",
        "    tk_img = ImageTk.PhotoImage(pil_img)\n",
        "    return tk_img"
      ],
      "metadata": {
        "id": "u5Jj-kvJk08m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import messagebox, Label\n",
        "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
        "from PIL import Image, ImageTk"
      ],
      "metadata": {
        "id": "VrYSMjC-iLgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tkinter app setup\n",
        "app = tk.Tk()\n",
        "app.title(\"Disease Predictor\")\n",
        "\n",
        "# Input field for symptoms\n",
        "symptoms_label = tk.Label(app, text=\"Enter symptoms:\")\n",
        "symptoms_label.pack()\n",
        "symptoms_entry = tk.Entry(app, width=50)\n",
        "symptoms_entry.pack()\n",
        "\n",
        "# plotting grap from shap\n",
        "image_label = Label(app)  # We'll update this with the plot images later\n",
        "image_label.pack()\n",
        "\n",
        "\n",
        "# Function to handle the 'Diagnose' action\n",
        "def on_diagnose():\n",
        "    symptoms = symptoms_entry.get()\n",
        "    embedding = generate_embeddings(symptoms)\n",
        "    top_matches = semantic_search(embedding, embeddings_database=None, top_k=1)[0]\n",
        "    closest_symptom = symptoms_db[top_matches[0]]\n",
        "    closest_embedding = embeddings_database[top_matches[0]]\n",
        "\n",
        "    embedding_tensor = torch.FloatTensor([closest_embedding])\n",
        "    prediction = predict_model(embedding_tensor)\n",
        "    disease = label_encoder.inverse_transform([prediction.argmax().item()])[0]  # Convert index to disease label\n",
        "    messagebox.showinfo(\"Prediction\", f\"Predicted Disease: {disease}\")\n",
        "    messagebox.showinfo(\"Top Results\",f\"closest match Disease: {closest_symptom}\")\n",
        "\n",
        "# Button to trigger diagnosis\n",
        "diagnose_button = tk.Button(app, text=\"Diagnose\", command=on_diagnose)\n",
        "diagnose_button.pack()\n",
        "\n",
        "# Function to handle the 'Show explanation' action\n",
        "def on_explain():\n",
        "    embedding_tensor = torch.FloatTensor([generate_embeddings(symptoms_entry.get())])\n",
        "    shap_values = explainer.shap_values(embedding_tensor)\n",
        "  # Create a SHAP plot\n",
        "    fig = shap.summary_plot(shap_values, embedding_tensor.numpy(), show=False)\n",
        "\n",
        "    # Convert to image and update the image_label\n",
        "    tk_img = fig_to_img(fig)\n",
        "    image_label.config(image=tk_img)\n",
        "    image_label.image = tk_img  # Keep a reference!\n",
        "\n",
        "explain_button = tk.Button(app, text=\"Show explanation\", command=on_explain)\n",
        "explain_button.pack()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4iFPSzhHiGvb",
        "outputId": "e5715f6c-84f4-4464-cf49-e36da4662584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "no display name and no $DISPLAY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-a4e6b5b6d58d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tkinter app setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Disease Predictor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Input field for symptoms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below were created during testing and does not add to the whole system"
      ],
      "metadata": {
        "id": "h9PeQcmIbxh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Function to calculate metrics and generate confusion matrix\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return precision, recall, f1, conf_matrix\n",
        "\n",
        "# Function to plot metrics and confusion matrix\n",
        "def plot_results(results, title_prefix=''):\n",
        "    fig, axs = plt.subplots(len(results), 2, figsize=(10, 5 * len(results)))\n",
        "    if len(results) == 1:\n",
        "        axs = [axs]\n",
        "\n",
        "    for idx, (noise_level, metrics) in enumerate(sorted(results.items())):\n",
        "        # Unpack metrics\n",
        "        svm_metrics, nn_metrics = zip(*metrics)\n",
        "        svm_accuracy = [m[0] for m in svm_metrics]\n",
        "        nn_accuracy = [m[1] for m in nn_metrics]\n",
        "\n",
        "        # Plot accuracy\n",
        "        axs[idx][0].plot(svm_accuracy, label='SVM Accuracy')\n",
        "        axs[idx][0].plot(nn_accuracy, label='NN Accuracy')\n",
        "        axs[idx][0].set_title(f'{title_prefix}Accuracy at Noise Level: {noise_level}')\n",
        "        axs[idx][0].set_xlabel('Fold Number')\n",
        "        axs[idx][0].set_ylabel('Accuracy')\n",
        "        axs[idx][0].legend()\n",
        "\n",
        "        # Calculate average confusion matrix for Neural Network\n",
        "        nn_conf_matrices = [calculate_metrics(y_test, m[2])[3] for m in nn_metrics]\n",
        "        avg_conf_matrix = np.mean(nn_conf_matrices, axis=0)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        sns.heatmap(avg_conf_matrix, annot=True, fmt=\".0f\", ax=axs[idx][1], cmap='Blues')\n",
        "        axs[idx][1].set_title(f'{title_prefix}Average Confusion Matrix (NN) at Noise Level: {noise_level}')\n",
        "        axs[idx][1].set_xlabel('Predicted Label')\n",
        "        axs[idx][1].set_ylabel('True Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "# Prepare Cross Validation\n",
        "def prepare_cv(data_frame, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    labels = LabelEncoder().fit_transform(data_frame['prognosis'])\n",
        "    return skf.split(np.stack(data_frame['embeddings'].values), labels)\n",
        "\n",
        "# Noise Addition\n",
        "def add_noise(data_frame, level=0.05):\n",
        "    noisy_data = data_frame.copy()\n",
        "    noise = np.random.normal(0, level, data_frame.shape)\n",
        "    noisy_data += noise\n",
        "    return noisy_data"
      ],
      "metadata": {
        "id": "F8VkT6_zOyMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Modifed the train_eval_models function to calculate additional metrics\n",
        "# def train_eval_models(data_frame, model, noise_levels=[0.0, 0.05, 0.1], n_splits=5):\n",
        "#     results = {}\n",
        "#     for noise_level in noise_levels:\n",
        "#         metrics_list = []\n",
        "#         noisy_embeddings = add_noise(np.stack(data_frame['embeddings'].values), noise_level)\n",
        "#         for train_idx, test_idx in prepare_cv(data_frame, n_splits):\n",
        "#             X_train, X_test = noisy_embeddings[train_idx], noisy_embeddings[test_idx]\n",
        "#             y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "#             scaler = StandardScaler()\n",
        "#             X_train_scaled = scaler.fit_transform(X_train)\n",
        "#             X_test_scaled = scaler.transform(X_test)\n",
        "#             svm_model = svm.SVC(kernel='linear')\n",
        "#             svm_model.fit(X_train_scaled, y_train)\n",
        "#             y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "#             svm_accuracy, svm_precision, svm_recall, svm_f1, _ = calculate_metrics(y_test, y_pred_svm)\n",
        "#             nn_model = DiseasePredictor()\n",
        "#             optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "#             criterion = nn.CrossEntropyLoss()\n",
        "#             dataset = TensorDataset(torch.tensor(X_train_scaled).float(), torch.tensor(y_train).long())\n",
        "#             loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "#             for epoch in range(10):  # Training loop\n",
        "#                 for inputs, labels in loader:\n",
        "#                     optimizer.zero_grad()\n",
        "#                     outputs = nn_model(inputs)\n",
        "#                     loss = criterion(outputs, labels)\n",
        "#                     loss.backward()\n",
        "#                     optimizer.step()\n",
        "#             nn_predictions = nn_model(torch.tensor(X_test_scaled).float()).argmax(1).numpy()\n",
        "#             nn_accuracy, nn_precision, nn_recall, nn_f1, _ = calculate_metrics(y_test, nn_predictions)\n",
        "#             metrics_list.append((svm_accuracy, nn_accuracy, y_test, nn_predictions))\n",
        "#         results[noise_level] = metrics_list\n",
        "#     return results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ZFCOTuYEDiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of running the enhanced script\n",
        "results = train_eval_models(data_frame, DiseasePredictor(), noise_levels=[0.0, 0.05, 0.1])\n",
        "plot_results(results, title_prefix='Experiment 1: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "DqwYtfuKMuCj",
        "outputId": "69125153-fe05-4135-90b8-c11dacccfcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'labels' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f1d4ac19bbb0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example of running the enhanced script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiseasePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Experiment 1: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-feec2179acfa>\u001b[0m in \u001b[0;36mtrain_eval_models\u001b[0;34m(data_frame, model, noise_levels, n_splits)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprepare_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'labels' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_model()\n"
      ],
      "metadata": {
        "id": "IEfdqkXKDf5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to add Gaussian noise\n",
        "def add_gaussian_noise(data, noise_level=0.01):\n",
        "    noise = np.random.normal(loc=0.0, scale=noise_level, size=data.shape)\n",
        "    return data + noise\n",
        "\n",
        "# Add noise to the original scaled data\n",
        "noise_level = 0.05  # 5% of the data scale\n",
        "X_noisy = add_gaussian_noise(X_scaled, noise_level=noise_level)\n",
        "\n",
        "# Split noisy data\n",
        "X_train_noisy, X_test_noisy, y_train_noisy, y_test_noisy = train_test_split(X_noisy, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Retrain SVM with linear kernel on noisy data\n",
        "svm_model_noisy = svm.SVC(kernel='linear')\n",
        "svm_model_noisy.fit(X_train_noisy, y_train_noisy)\n",
        "y_pred_noisy = svm_model_noisy.predict(X_test_noisy)\n",
        "\n",
        "# Evaluate the noisy model\n",
        "accuracy_noisy = accuracy_score(y_test_noisy, y_pred_noisy)\n",
        "classification_rep_noisy = classification_report(y_test_noisy, y_pred_noisy)\n",
        "\n",
        "# Test SVM with RBF kernel on both original and noisy data\n",
        "svm_model_rbf = svm.SVC(kernel='rbf')\n",
        "svm_model_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_model_rbf.predict(X_test)\n",
        "\n",
        "svm_model_rbf_noisy = svm.SVC(kernel='rbf')\n",
        "svm_model_rbf_noisy.fit(X_train_noisy, y_train_noisy)\n",
        "y_pred_rbf_noisy = svm_model_rbf_noisy.predict(X_test_noisy)\n",
        "\n",
        "# Evaluate RBF model on clean data\n",
        "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "classification_rep_rbf = classification_report(y_test, y_pred_rbf)\n",
        "\n",
        "# Evaluate RBF model on noisy data\n",
        "accuracy_rbf_noisy = accuracy_score(y_test_noisy, y_pred_rbf_noisy)\n",
        "classification_rep_rbf_noisy = classification_report(y_test_noisy, y_pred_rbf_noisy)\n",
        "\n",
        "# Collect all results for comparison\n",
        "results = {\n",
        "    \"Linear SVM on Noisy Data\": (accuracy_noisy, classification_rep_noisy),\n",
        "    \"RBF SVM on Clean Data\": (accuracy_rbf, classification_rep_rbf),\n",
        "    \"RBF SVM on Noisy Data\": (accuracy_rbf_noisy, classification_rep_rbf_noisy)\n",
        "}\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "id": "NFgVtKZqKJ_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "jfhzs [I 2024-04-20 23:02:52,281] Trial 83 finished with value: 0.6940219402313232 and parameters: {'lr': 0.0006312703277951093, 'num_layers': 3, 'num_units': 462, 'dropout_rate': 0.0015024972313569286, 'decay': 0.9053013456459507, 'num_epochs': 55, 'batch_size': 12}. Best is trial 83 with value: 0.6940219402313232.\n"
      ],
      "metadata": {
        "id": "hppWldc41aDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best hyperparameters:  {'lr': 0.0006312703277951093, 'num_layers': 3, 'num_units': 462, 'dropout_rate': 0.0015024972313569286, 'decay': 0.9053013456459507, 'num_epochs': 55, 'batch_size': 12}\n",
        "\n"
      ],
      "metadata": {
        "id": "M-zT01BM1kUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ff4FG7oWnuiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster embeddings dimensions\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(embeddings_database)\n",
        "clusters = kmeans.labels_\n",
        "\n",
        "# Use GPT-Neo to describe each cluster\n",
        "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE70-n8Sa7rY",
        "outputId": "f3618259-b89f-4b2e-dfa1-a184f69d5481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is still under evaluation on where to use it in final application or not"
      ],
      "metadata": {
        "id": "73e52iMvnoPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def describe_cluster(index):\n",
        "    cluster_center = kmeans.cluster_centers_[index]\n",
        "    prompt = f\"Describe the following data characteristics in simple terms: {cluster_center.tolist()}\"\n",
        "    inputs = gpt_tokenizer.encode(prompt, return_tensors='pt')\n",
        "    outputs = gpt_model.generate(inputs, max_length= 9000, num_return_sequences=1)\n",
        "    return gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "cluster_descriptions = [describe_cluster(i) for i in range(10)]\n"
      ],
      "metadata": {
        "id": "KEsxcJMHyYJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "327b89b9-4769-41e3-bd3e-95bbacd7337e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-41a05e45a19e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcluster_descriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdescribe_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-41a05e45a19e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcluster_descriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdescribe_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-41a05e45a19e>\u001b[0m in \u001b[0;36mdescribe_cluster\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Describe the following data characteristics in simple terms: {cluster_center.tolist()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m9000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY_SEARCH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0;31m# 11. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1545\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2405\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2235\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KOpmLraFlYx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is for testing and will not be part of the final application"
      ],
      "metadata": {
        "id": "F6B883BKngVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'disease_model' is your trained model and 'embeddings_database' is available\n",
        "# Initialize SHAP explainer (should ideally be done outside the main app loop to save resources)\n",
        "\n",
        "print('Disease Diagnosis from Symptoms')\n",
        "print('Please enter the symptoms you are experiencing:')\n",
        "yes = True\n",
        "\n",
        "while yes:\n",
        "    symptoms = input(\"Symptoms\")\n",
        "    explain = \"\"\n",
        "    embedding = generate_embeddings(symptoms)\n",
        "    top_matches = semantic_search(embedding, embeddings_database, top_k=1)\n",
        "    closest_symptom = symptoms_db[top_matches[0]]\n",
        "    closest_embedding = embeddings_database[top_matches[0]]\n",
        "\n",
        "    embedding_tensor = torch.FloatTensor([closest_embedding])\n",
        "    prediction = predict_model(embedding_tensor)\n",
        "    disease = label_encoder.inverse_transform([prediction.argmax().item()])[0]\n",
        "\n",
        "    print(f'Closest Matched Symptom Description: {closest_symptom}')\n",
        "    print(f'Predicted Disease: {disease}')\n",
        "\n",
        "    explain = input(\"do you want explaination: \")\n",
        "    if explain == \"yes\":\n",
        "            # SHAP Value Calculation\n",
        "          shap_values = explainer.shap_values(embedding_tensor)\n",
        "          pyplot(shap.force_plot(explainer.expected_value[0], shap_values[0], feature_names=['Embedding Dimensions']))\n",
        "          pyplot(shap.summary_plot(shap_values, X_test_tensor.numpy(), feature_names =['Embedding Dimensions'] ))\n",
        "          showplot()"
      ],
      "metadata": {
        "id": "y-FIbgs3i5Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02117fc4-db4a-4700-8992-75ea1c2c5109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is just for testing and will not be used in the final code"
      ],
      "metadata": {
        "id": "cSsc62Oq91PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some statistics of your data to check if it's loaded and scaled correctly\n",
        "print(\"Feature statistics:\")\n",
        "print(\"Mean:\", X_tensor.mean())\n",
        "print(\"Std deviation:\", X_tensor.std())\n",
        "print(\"Max value:\", X_tensor.max())\n",
        "print(\"Min value:\", X_tensor.min())\n",
        "\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(torch.bincount(y_tensor))\n"
      ],
      "metadata": {
        "id": "9hFf7vu87qP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is just for testing and will not be used in the final code"
      ],
      "metadata": {
        "id": "3zAkoE3D95h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model architecture\n",
        "print(model)\n",
        "\n",
        "# Check if any weights or biases have become NaN or inf\n",
        "for name, param in model.named_parameters():\n",
        "    if torch.isnan(param).any() or torch.isinf(param).any():\n",
        "        print(f\"Parameter {name} contains NaN or inf\")\n"
      ],
      "metadata": {
        "id": "WTI97NhS7gCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is just for testing and will not be used in the final code"
      ],
      "metadata": {
        "id": "g2lsZvpq96iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed training loop with debug information\n",
        "for epoch in range(100):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        if torch.isnan(loss) or loss == 0:\n",
        "            print(f\"NaN or zero loss at epoch {epoch+1}, batch {i+1}\")\n",
        "            print(\"Outputs:\", outputs)\n",
        "            print(\"Labels:\", labels)\n",
        "            break  # Break out of the loop to investigate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "nfPjMmqS7s53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is just for testing and will not be used in the final code"
      ],
      "metadata": {
        "id": "HP1926Rt-AuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check optimizer's current state\n",
        "print(\"Optimizer state:\", optimizer.state_dict())\n"
      ],
      "metadata": {
        "id": "F3QxLzJF7wIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is just for testing and will not be used in the final code"
      ],
      "metadata": {
        "id": "anxg5ah5-B90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dropout rate in the model definition\n",
        "print(\"Dropout rate:\", model.dropout.p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp7L4vfp7zff",
        "outputId": "be494151-7ca1-43a5-e494-5b36005cacf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropout rate: 0.025584912658500554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optuna similar to gridsearch to find best hyperparameters"
      ],
      "metadata": {
        "id": "_GTQI1RZy0Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-xGOG6gz-BJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}